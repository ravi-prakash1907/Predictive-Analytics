{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment analysis basic.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORCBhqXkEZlA6ilPA53+06",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-prakash1907/Predictive-Analytics/blob/tuts/Analysis/sentiment_analysis_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIE8sI1eBywc"
      },
      "source": [
        "# Sentiment Analysis in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksAodEa1EUfi"
      },
      "source": [
        "### It involves few steps:\n",
        "\n",
        "Taking following sentace as example:  \n",
        "  - **_The movie was great!_**  \n",
        "\n",
        "**1. Tokenization:**  \n",
        "> Splitting into words.  \n",
        "> Dividing para in statements.  \n",
        "> After tokenization, sentence will be:  \n",
        "> * The  \n",
        "> * movie  \n",
        "> * was  \n",
        "> * great  \n",
        "> * !  \n",
        "\n",
        "**2. Cleaning:**  \n",
        "> Removing special chars., unnecessary words etc..  \n",
        "> After cleaning, sentence will be: \n",
        "> * The  \n",
        "> * movie  \n",
        "> * was  \n",
        "> * great  \n",
        "\n",
        "**3. Stopwords' Removal**  \n",
        "> Removing unnecessary words like articles etc..  \n",
        "> After stopwords' removal, sentence will be: \n",
        "> * movie  \n",
        "> * great \n",
        "\n",
        "**4. Classification:**  \n",
        "> Identifying as +ve or -ve  \n",
        ">   - Sentiments +ve(1), -ve(-1), or nutral(0) assigned to each word  \n",
        ">  \n",
        "> Requires the usage of _bag of words_ \n",
        "> May use _lexicons_ (dictionary of pre-classified words with sentiments)  \n",
        "> Above mentioned waay are _Supervised Learning Methods_  \n",
        "> Model evaluation:  \n",
        ">   - Accuracy score  \n",
        ">   - Errors etc..  \n",
        ">  \n",
        "> After stopwords' removal, sentence will be: \n",
        "> * movie = __0__  \n",
        "> * great = __1__  \n",
        "\n",
        "**5. Calculation:**  \n",
        "> Combining statement, all the sentiment values are added  \n",
        "> After stopwords' removal, sentence will be: \n",
        "> * 0 + 1 = __+1__  \n",
        "> * Hence, sentance is __+ve__  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs_WhqLhBmbq",
        "outputId": "375bfa00-8df4-4b97-9ca6-cb59f2751b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## adding a python library textblob\n",
        "## used for processing textual data\n",
        "# !pip install textblob"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2cpwIoCIsdg"
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agDogx8yI4ZW"
      },
      "source": [
        "Feedback1 = \"The food was awesome!\"\n",
        "Feedback2 = \"Pizza at Hudson Lane was good.\"\n",
        "blob1 = TextBlob(Feedback1)\n",
        "blob2 = TextBlob(Feedback2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgixHAKpJSld",
        "outputId": "4b04d934-156e-4ca9-b8e8-4171dd470fa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(blob1.sentiment)\n",
        "print(blob2.sentiment)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment(polarity=1.0, subjectivity=1.0)\n",
            "Sentiment(polarity=0.7, subjectivity=0.6000000000000001)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHyT6QxhJhIn"
      },
      "source": [
        "**Polarity:** How +ve/-ve the sentence is?  \n",
        "**Subjectivity:** Tells about personaal feelings, views etc..  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3U2x2pQJX-a",
        "outputId": "e56b094c-dbfc-4435-ef77-dfe800b648f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## look and compare here\n",
        "tempSentence = \"It is raining in New York!!\"\n",
        "blobTemp = TextBlob(tempSentence)\n",
        "print(blobTemp.sentiment)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment(polarity=0.2130681818181818, subjectivity=0.45454545454545453)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}